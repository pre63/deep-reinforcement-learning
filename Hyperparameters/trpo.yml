# Tuned
Pendulum-v1:
  policy: 'MlpPolicy'
  n_timesteps: 100000
  n_envs: 2
  n_steps: 1024
  gamma: 0.9
  n_critic_updates: 15
  use_sde: True
  sde_sample_freq: 4

# Tuned
LunarLanderContinuous-v3:
  policy: 'MlpPolicy'
  n_timesteps: 100000
  n_envs: 2
  batch_size: 32
  n_steps: 2048
  gamma: 0.995
  learning_rate: 0.0014
  n_critic_updates: 20
  cg_max_steps: 25
  target_kl: 0.01
  gae_lambda: 0.92
  net_arch: medium
  activation_fn: relu

Ant-v5:
  policy: 'MlpPolicy'
  n_timesteps: 100000
  normalize: true
  n_envs: 2
  batch_size: 128
  n_steps: 1024
  gamma: 0.99
  gae_lambda: 0.95
  sub_sampling_factor: 1
  cg_max_steps: 25
  cg_damping: 0.1
  n_critic_updates: 20
  learning_rate: !!float 1e-3

Humanoid-v3:
  policy: 'MlpPolicy'
  n_timesteps: 100000
  normalize: true
  n_envs: 2
  batch_size: 128
  n_steps: 1024
  gamma: 0.99
  gae_lambda: 0.95
  sub_sampling_factor: 1
  cg_max_steps: 25
  cg_damping: 0.1
  n_critic_updates: 20
  learning_rate: !!float 1e-3

InvertedDoublePendulum-v5:
  policy: 'MlpPolicy'
  n_timesteps: 100000
  normalize: true
  n_envs: 2
  batch_size: 128
  n_steps: 1024
  gamma: 0.99
  gae_lambda: 0.95
  sub_sampling_factor: 1
  cg_max_steps: 25
  cg_damping: 0.1
  n_critic_updates: 20
  learning_rate: !!float 1e-3

RocketLander-v0:
  policy: 'MlpPolicy'
  n_timesteps: 100000
  normalize: true
  n_envs: 2
  batch_size: 128
  n_steps: 1024
  gamma: 0.99
  gae_lambda: 0.95
  sub_sampling_factor: 1
  cg_max_steps: 25
  cg_damping: 0.1
  n_critic_updates: 20
  learning_rate: !!float 1e-3

